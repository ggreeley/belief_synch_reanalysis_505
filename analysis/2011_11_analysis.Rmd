---
title: 'Analysis: Revisiting Vlasceanu et al. (2020)'
author: "Garrett D. Greeley"
date: "Document Last Generated: `r format(Sys.time(), '%A, %B %d, %Y')`"
output:
  html_document:
    code_folding: hide
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

This document/code accomplishes several tasks. In order, it:

1) Step
2) Step
3) Step
4) Step

If the repo is cloned and the file knits properly, the data from data/analysis is read, visualized, and analyzed.

# Libraries

Libraries that may be needed for analysis, visualization, and additional processing:

```{r}
# modeling
library(lme4)
library(betareg)
library(brms)

# aesthetic
library(showtext)
# https://www.fontsquirrel.com/fonts/latin-modern-roman
font_add(family = "lmroman",
         regular = "/Library/Fonts/lmroman10-regular-webfont.ttf")
font_add(family = "lmroman_b",
         regular = "/Library/Fonts/lmroman10-bold-webfont.ttf")
showtext_auto()

# general
library(tidyverse)
```

# Functions

Helper functions:

```{r}
source(
  here::here("processing", "functions.R")
  )

source(
  here::here("analysis", "functions.R")
  )
```

# Data

Read the wrangled data generated by 2021-11_processing.Rmd (see that file for creation and notes):

```{r}
beliefs <- read_csv(
  here::here("data", "analysis", "2021-11_long_beliefs.csv")
  )
rschange <- read_csv(
  here::here("data", "analysis", "2021-11_long_rschange.csv")
  )
synch <- read_csv(
  here::here("data", "analysis", "2021-11_long_synch.csv")
  )
```

# Basic Descriptives

First, let's clean up the participant codes a bit. In the original study, codes were generated by asking participants to provide a combination of their birthplace and birthday - the components were broad enough as to (probably) not be identifiable (e.g., city and month), but I'd prefer something a little more standardized/aesthetic:

```{r participant codes}
beliefs <- beliefs %>%
  mutate(participant_code = participant_code %>%
           as.factor() %>%
           forcats::fct_anon(prefix = "p0"))
```

What is the $N$ (should match manuscript; 168)?:

```{r sample size}
# N = 168 (matches)
beliefs %>%
  group_by(participant_code) %>%
  slice_head(n = 1) %>%
  nrow()

# shorter way, but perhaps less explicit/safe
n_distinct(beliefs$participant_code)
```

Other demographics:

```{r}
indiv_dat <- beliefs %>%
  group_by(participant_code) %>%
  slice_head(n = 1) %>%
  ungroup()

indiv_dat %>%
  count(what_is_your_gender) %>%
  mutate(perc = n / sum(n))

indiv_dat %>%
  mutate(what_is_your_native_language = str_to_lower(what_is_your_native_language)) %>%
  count(what_is_your_native_language) %>%
  mutate(perc = n / sum(n)) %>%
  arrange(-n) %>%
  view()

indiv_dat %>%
  summarise(mean_age = mean(how_old_are_you),
            sd_age = sd(how_old_are_you),
            min_age = min(how_old_are_you),
            max_age = max(how_old_are_you))

indiv_dat %>%
  summarise(mean_politics = mean(political_views),
            sd_politics = sd(political_views),
            min_politics = min(political_views),
            max_politics = max(political_views))
```

Demographic combinations. Political distribution pretty equal across sexes, age, sex/age.

```{r}
indiv_dat %>%
  group_by(what_is_your_gender, political_views) %>%
  count() %>%
  ungroup() %>%
  ggplot(aes(x = political_views, y = n, fill = what_is_your_gender)) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = 1:7) +
  theme_light()

indiv_dat %>%
  ggplot(aes(x = political_views, y = how_old_are_you)) +
  geom_jitter() +
  facet_wrap(~ what_is_your_gender) +
  scale_x_continuous(breaks = 1:7) +
  theme_light()
```

# Belief Change

## Visualizations

Participant level ratings for each item by rating type (scientific support or accuracy):

```{r}
# rating theme
raw_rating_theme <- function(...) {
  theme_light() +
  theme(plot.title = element_text(family = "lmroman", size = 24, margin = margin(0,0,30,0)),
        title = element_text(family = "lmroman", size = 20),
        axis.text.x = element_text(family = "lmroman", size = 12),
        axis.text.y = element_text(family = "lmroman", size = 12),
        legend.text = element_text(family = "lmroman", size = 14),
        strip.text = element_text(family = "lmroman", color = "black", size = 16),
        strip.background = element_rect(fill = "white", color = "black"))
}

raw_rating_plot_a <- beliefs %>%
  select(participant_code, phase, rating_type, item_category, item_code, raw_rating) %>%
  filter(phase == "p1") %>%
  mutate(rating_type = str_to_title(rating_type),
         raw_rating = as.character(raw_rating),
         raw_rating = case_when(raw_rating == 1 ~ "1 (not at all/definitely not)",
                                raw_rating == 7 ~ "7 (very much so/definitely yes)",
                                TRUE ~ raw_rating)) %>%
  ggplot(aes(x = item_code, y = participant_code, fill = raw_rating)) +
  geom_tile() +
  scale_fill_viridis_d(option = "magma") +
  labs(title = "A) Phase #1 Ratings",
       x = "Statement Code",
       y = "Participant (One Per Row)",
       fill = "Raw Rating") +
  scale_y_discrete(breaks = c("p0001", "p0084", "p0168")) +
  facet_wrap(~ rating_type, scales = "free") +
  raw_rating_theme()

raw_rating_plot_b <- beliefs %>%
  select(participant_code, phase, rating_type, item_category, item_code, raw_rating) %>%
  filter(phase == "p2") %>%
  mutate(rating_type = str_to_title(rating_type),
         raw_rating = as.character(raw_rating),
         raw_rating = case_when(raw_rating == 1 ~ "1 (not at all/definitely not)",
                                raw_rating == 7 ~ "7 (very much so/definitely yes)",
                                TRUE ~ raw_rating)) %>%
  ggplot(aes(x = item_code, y = participant_code, fill = raw_rating)) +
  geom_tile() +
  scale_fill_viridis_d(option = "magma") +
  labs(title = "B) Phase #2 Ratings",
       x = "Statement Code",
       y = "Participant (One Per Row)",
       fill = "Raw Rating") +
  scale_y_discrete(breaks = c("p0001", "p0084", "p0168")) +
  facet_wrap(~ rating_type, scales = "free") +
  raw_rating_theme()

raw_rating_plot_a
raw_rating_plot_b
```

Save:

```{r save heatmaps, include=FALSE}
#ggsave(filename = here::here(
#  "figs",
#  "figs_final",
#  paste0(format(Sys.time(), "%Y-%m-%d_%H-%M_%S_"), "raw_rating_plot_a", ".png")
#  ),
#  plot = raw_rating_plot_a,
#  width = 14)

#ggsave(filename = here::here(
#  "figs",
#  "figs_final",
#  paste0(format(Sys.time(), "%Y-%m-%d_%H-%M_%S_"), "raw_rating_plot_b", ".png")
#  ),
#  plot = raw_rating_plot_b,
#  width = 14)
```

Participant level ratings for each item by rating type **and** category (N, A, H, V; meaning unknown). Can you spot the myths?:

```{r}
beliefs %>%
  select(participant_code, phase, rating_type, item_category, item_code, raw_rating) %>%
  mutate(rating_type = str_to_title(rating_type),
         raw_rating = as.character(raw_rating),
         raw_rating = case_when(raw_rating == 1 ~ "1 (not at all/definitely not)",
                                raw_rating == 7 ~ "7 (very much so/definitely yes)",
                                TRUE ~ raw_rating)) %>%
  ggplot(aes(x = item_code, y = participant_code, fill = raw_rating)) +
  geom_tile() +
  scale_fill_viridis_d(option = "magma") +
  labs(title = "B) Phase #2 Ratings",
       x = "Statement Code",
       y = "Participant (One Per Row)",
       fill = "Raw Rating") +
  scale_y_discrete(breaks = c("p0001", "p0084", "p0168")) +
  facet_wrap(~ rating_type + item_category, scales = "free", ncol = 2) +
  raw_rating_theme()
```

## Phase Correlations

```{r}
belief_cor <- beliefs %>%
  select(participant_code, condition, rating_type, item_category, item_code, phase, raw_rating) %>%
  pivot_wider(names_from = phase,
              values_from = raw_rating)

#cor(belief_cor$p1, belief_cor$p2)

indiv_accuracy_phase_cor <- belief_cor %>%
  filter(rating_type == "accuracy") %>%
  group_by(participant_code) %>%
  group_split() %>%
  map(~ broom::tidy(cor.test(.$p1, .$p2))) %>%
  bind_rows()
  
indiv_science_phase_cor <- belief_cor %>%
  filter(rating_type == "science") %>%
  group_by(participant_code) %>%
  group_split() %>%
  map(~ broom::tidy(cor.test(.$p1, .$p2))) %>%
  bind_rows()
```

Plot:

```{r}

indiv_accuracy_phase_cor %>%
  mutate(tmp_particpant = row_number(),
         var_cor = "Accuracy of Statement") %>%
  bind_rows(.,
            indiv_science_phase_cor %>%
              mutate(tmp_particpant = row_number(),
                     var_cor = "Scientific Support for Statement")) %>%
  group_by(var_cor) %>%
  mutate(mean_cor = mean(estimate, na.rm = TRUE)) %>%
  ggplot(aes(x = tmp_particpant, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low,
                ymax = conf.high)) +
  facet_wrap(~ var_cor) +
  geom_hline(aes(yintercept = mean_cor),
             color = "red",
             size = 2) +
  labs(x = "Participant",
       y = "Pearson Correlation (r)") +
  raw_rating_theme()
  #ggthemes::theme_economist()
    
```

## Analyses (#1)

First, missing data?

```{r}
belief_cor %>%
  filter(is.environment(p1)) %>%
  nrow()

belief_cor %>%
  filter(is.environment(p2)) %>%
  nrow()
```

No. Impressive given 168 participants and 48 total ratings per phase (e.g., $168_{participants} \times 2_{phases} \times 24_{questions/phase} \times 2_{ratings/question} = 16128$ data points), but it was a laboratory study so reasonable (participants may not have been able to advance to subsequent questions without providing ratings).

The plots above suggest generally increasing believability across the two phases. 

Prep data for analyses. First, merge in myth/fact information to the belief_cor data and mutate a "change" indicator column for mixed-effect logistic regression. Second, trim down "belief" data to only columns that should be included for modeling (mixed-effect linear regression; possibly mixed-effect multinomial logistic regression [1-7 scale is ordinal, but 7 levels is *normally* treated as continuous - at least it's not 3/4/5! - inclusion of this model depends on my motivation over the next few days])

```{r}
belief_logit_dat <- belief_cor %>%
  left_join(.,
            beliefs %>%
              select(participant_code, condition, item_category,
                     rating_type, political_views, fact_or_myth, item_code),
            by = c("participant_code", "condition", "item_category", "item_code", "rating_type")) %>%
  # unclear why rows doubling despite very specific merge criteria
  # for now, solve by only keeping one of each doubled row
  group_by(participant_code, rating_type, item_category, item_code) %>%
  slice_head(n = 1) %>%
  ungroup() %>%
  mutate(rating_diff = p2 - p1,
         rating_change = ifelse(rating_diff == 0, 0, 1),
         rating_direction = ifelse(rating_diff > 0, "increase",
                                   ifelse(rating_diff < 0, "decrease",
                                          "same")
                                   ),
         condition = as.factor(condition))

belief_multinom_dat <- beliefs %>%
  select(participant_code, condition, item_category,
         rating_type, political_views, fact_or_myth,
         phase, item_code, raw_rating) %>%
  # in case participant slopes desired on phase
  mutate(phase_num = parse_number(phase) - 1)
```

### Mixed Effect Logistic Regression (Frequentist)

Empty/Null model to assess participant and item intercept variability.

Note that this random effect structure is *crossed*: all participants provided multiple ratings on all items.

```{r}
belief_logit_dat %>%
  count(rating_change) # no excessive 1s/0s
```

```{r}
belief_change_null <- glmer(rating_change ~ 1 + (1 | participant_code) + (1 | item_code),
                            family = binomial(link = "logit"),
                            data = belief_logit_dat)

summary(belief_change_null)
```

ICC - note that this ICC represents the variance in belief change (1/0) that is between participants **and** items. Thus, about 10.5% of the variance in belief change is between participants (person-to-person variability) and between items (item-to-item variability). 

```{r}
# store variances from each random effect
belief_change_null_part_var <- 0.28736
belief_change_null_item_var <- 0.09833

# calculate manually (performance::icc() only gives 1 value, unclear how it's derived)
# see ./analysis/functions.R
# between participants
icc_logit(rand_effect_var = belief_change_null_part_var)
# between items
icc_logit(rand_effect_var = belief_change_null_item_var)

# combining random effect variances
(belief_change_null_part_var + belief_change_null_item_var) /
  ((belief_change_null_part_var + belief_change_null_item_var) + (pi^2 / 3))

# this matches random effect combo
performance::icc(belief_change_null)
```

Separating these (in the code chunk above), it appears the largest chunk of variance (other than *within-person* variance) is between participants. See `belief_change_null_part_var / (belief_change_null_part_var + (pi^2 / 3))`, which gives 0.08 (~8% of variability in belief change is between participants; ~3% is between items).

This has little bearing on the conditional models that follow. This mostly just demonstrates that a mixed model is indeed called for here, given the variance in the outcome absorbed by the random effects.

Now fit conditional models. The first includes the fixed effects central to the study (condition, rating type, and fact/myth status of the item). The second includes additional covariates.

```{r}
# conditional model w/ central predictors
belief_change_cond_1 <- glmer(rating_change ~ 1 +
                              condition +
                              rating_type +
                              fact_or_myth +
                              (1 | participant_code) + (1 | item_code),
                            family = binomial(link = "logit"),
                            data = belief_logit_dat)

summary(belief_change_cond_1)

# adding covariates
belief_change_cond_2 <- glmer(rating_change ~ 1 +
                              condition +
                              rating_type +
                              fact_or_myth +
                              item_category +
                              political_views +
                              (1 | participant_code) + (1 | item_code),
                            family = binomial(link = "logit"),
                            data = belief_logit_dat)

summary(belief_change_cond_2)
```

Inclusion of covariates (item category and political views) has an interesting effect. The "political views" fixed effect is statistically significant, default category contrasts (each vs. "a") are not, and AIC and BIC increased.

Perhaps most interestingly, there is not much of a difference in belief change between conditions (not statistically significant, at least). But there **is** a difference in belief change as a function of "rating type" - that is, accuracy vs. scientific support ratings. 

```{r}
broom.mixed::tidy(belief_change_cond_2) %>%
  mutate(estimate_oddratio = ifelse(effect == "fixed", exp(estimate), NA),
         .after = estimate) %>%
  select(-statistic)

#stargazer::stargazer(belief_change_cond_2,
#                     type = "latex",
#                     out = here::here("figs", "figs_temp", "belief_change_cond_2_tab.tex"))
```

Predict:

```{r}
belief_logit_dat %>%
  mutate(full_mod_predict_log = predict(belief_change_cond_2),
         full_mod_predict_log_norandef = predict(belief_change_cond_2,
                                                 re.form = NA),
         full_mod_predict_prob = predict(belief_change_cond_2, type = "response"),
         full_mod_predict_prob_norandef = predict(belief_change_cond_2, type = "response",
                                                  re.form = NA))
```

Plots. A lot of code repetition here, could modularize later:

```{r}
# belief change probability as a function of condition (ns)
belief_change_plot_a <- emmeans::emmeans(belief_change_cond_2,
                 specs = ~ condition,
                 type = "response") %>%
  data.frame() %>%
  ggplot(aes(x = condition, y = prob, fill = condition)) +
  geom_bar(stat = "identity",
           alpha = 0.8) +
  geom_errorbar(aes(ymin = asymp.LCL,
                    ymax = asymp.UCL),
                width = 0.25,
                color = "black") +
  scale_fill_manual(values = c("darkred", "#000080")) +
  coord_cartesian(ylim = c(0.3, 0.8)) +
  labs(title = "A) Condition",
       fill = "Condition",
       x = "Condition",
       y = "Rating Change Probability") +
  raw_rating_theme()

# belief change probability as a function of item being fact/myth (sig)
belief_change_plot_b <- emmeans::emmeans(belief_change_cond_2,
                 specs = ~ fact_or_myth,
                 type = "response") %>%
  data.frame() %>%
  mutate(fact_or_myth = str_to_title(fact_or_myth)) %>%
  ggplot(aes(x = fact_or_myth, y = prob)) +
  geom_bar(stat = "identity",
           fill = "#134e13",
           alpha = 0.8) +
  geom_errorbar(aes(ymin = asymp.LCL,
                    ymax = asymp.UCL),
                width = 0.25,
                color = "black") +
  coord_cartesian(ylim = c(0.3, 0.8)) +
  labs(title = "B) Fact vs. Myth",
       x = "Fact vs. Myth",
       y = "Rating Change Probability") +
  raw_rating_theme()

# belief change probability as a function of rating type (sig)
belief_change_plot_c <- emmeans::emmeans(belief_change_cond_2,
                 specs = ~ rating_type,
                 type = "response") %>%
  data.frame() %>%
  mutate(rating_type = str_to_title(rating_type)) %>%
  ggplot(aes(x = rating_type, y = prob)) +
  geom_bar(stat = "identity",
           fill = "#134e13",
           alpha = 0.8) +
  geom_errorbar(aes(ymin = asymp.LCL,
                    ymax = asymp.UCL),
                width = 0.25,
                color = "black") +
  coord_cartesian(ylim = c(0.3, 0.8)) +
  labs(title = "C) Rating Type",
       x = "Rating Type",
       y = "Rating Change Probability") +
  raw_rating_theme()

# belief change probability as a function of item category
belief_change_plot_d <- emmeans::emmeans(belief_change_cond_2,
                 specs = ~ item_category,
                 type = "response") %>%
  data.frame() %>%
  ggplot(aes(x = item_category, y = prob)) +
  geom_bar(stat = "identity",
           fill = "#134e13",
           alpha = 0.8) +
  geom_errorbar(aes(ymin = asymp.LCL,
                    ymax = asymp.UCL),
                width = 0.25,
                color = "black") +
  coord_cartesian(ylim = c(0.3, 0.8)) +
  labs(title = "D) Item Category",
       x = "Item Category",
       y = "Rating Change Probability") +
  raw_rating_theme()

# belief change probability as a function of political views
belief_change_plot_e <- emmeans::emmeans(belief_change_cond_2,
                 specs = ~ political_views,
                 at = list(political_views = 1:7),
                 type = "response") %>%
  data.frame() %>%
  ggplot(aes(x = political_views, y = prob)) +
  geom_ribbon(aes(ymin = asymp.LCL,
                ymax = asymp.UCL),
              fill = "lightgray",
              alpha = 0.30) +
  geom_line(size = 2,
            color = "#134e13") +
  scale_x_continuous(breaks = 1:7) +
  coord_cartesian(ylim = c(0.3, 0.8)) +
  labs(title = "E) Political Views",
       x = "Political Views",
       y = "Rating Change Probability") +
  raw_rating_theme()

# combination - while no interaction explored, nice to see in one place
belief_change_plot_f <- emmeans::emmeans(belief_change_cond_2,
                 specs = ~ political_views + condition + fact_or_myth,
                 at = list(political_views = 1:7),
                 type = "response") %>%
  data.frame() %>% 
  mutate(fact_or_myth = str_to_title(fact_or_myth)) %>%
  ggplot(aes(x = political_views, y = prob, color = condition)) +
  geom_ribbon(aes(ymin = asymp.LCL,
                ymax = asymp.UCL),
              fill = "lightgray",
              alpha = 0.30) +
  geom_line(size = 2) +
  scale_color_manual(values = c("darkred", "#000080")) +
  facet_wrap(~ fact_or_myth + condition, nrow = 1) +
  coord_cartesian(ylim = c(0.3, 0.8)) +
  labs(title = "F) Combo Plot",
       color = "Condition",
       x = "Political Views",
       y = "Rating Change Probability") +
  raw_rating_theme()
```

View / construct plots. Proud of this one:

```{r}
library(patchwork)
belief_change_abcdef <- 
  (belief_change_plot_a / belief_change_plot_b / belief_change_plot_c) |
  (belief_change_plot_d / belief_change_plot_e / belief_change_plot_f) 

belief_change_abcdef

#ggsave(filename = here::here(
#  "figs",
#  "figs_final",
#  paste0(format(Sys.time(), "%Y-%m-%d_%H-%M_%S_"), "logit_mod_population_effects", ".png")
#  ),
#  plot = belief_change_abcdef,
#  width = 14,
#  height = 12)
```

### Mixed Effect Logistic Regression (Bayesian)

```{r}
belief_change_cond_2_brm <- brm(rating_change ~ 1 +
      condition +
      rating_type +
      fact_or_myth +
      item_category +
      political_views +
      (1 | participant_code) + (1 | item_code),
    family = binomial(link = "logit"),
    data = belief_logit_dat,
    file = "analysis/brms_fits/belief_change_cond_2_brm")

summary(belief_change_cond_2_brm)
plot(belief_change_cond_2_brm)
```

## Analysis (#2)

### Mixed Effect Ordinal Logistic Regression (Frequentist)

So, 7 levels is wild to start with for my *first* mixed effect ordinal regression. Thus, sticking with same logit data as before but using "rating_change" as outcome, with 3 ordinal levels: decrease, same, increase.

```{r}
belief_logit_dat %>%
  count(rating_direction) # no excessive levels

# for ordinal::clmm, rating_direction needs to be a factor
belief_logit_dat$rating_direction <- factor(belief_logit_dat$rating_direction,
                                               levels = c("decrease", "same", "increase"))

levels(belief_logit_dat$rating_direction)
```

Empty/Null model:

```{r}
belief_ord_null <- ordinal::clmm(rating_direction ~ 1 + (1 | participant_code) + (1 | item_code),
              link = "logit", # proportional odds
              data = belief_logit_dat)

summary(belief_ord_null)
```

Conditional models:

```{r}
belief_ord_cond_1 <- ordinal::clmm(rating_direction ~ 1 +
                                     condition +
                                     rating_type +
                                     fact_or_myth +
                                     (1 | participant_code) + (1 | item_code),
              link = "logit", # proportional odds
              data = belief_logit_dat)

summary(belief_ord_cond_1)

belief_ord_cond_2 <- ordinal::clmm(rating_direction ~ 1 +
                                     condition +
                                     rating_type +
                                     fact_or_myth +
                                     item_category +
                                     political_views +
                                     (1 | participant_code) + (1 | item_code),
              link = "logit", # proportional odds
              data = belief_logit_dat)

summary(belief_ord_cond_2)
```

Odds ratios:

```{r}
exp(belief_ord_cond_2$coefficients)
```

As for table, have to make manually since `clmm::clmm()` is not a supported model object type.

Get probability estimates and or relative probabilities. Could not find a way to get predicted ordinal category probabilities as a function of predictors with model object + emmeans. `brms::conditional_effects` makes this easy. The commented out codes represent some efforts. Note that the first few attempts give (what I think are) the probabilities of being in a higher category (e.g., same or increased rating, relative to decreasing).:

```{r}
emmeans::emmeans(belief_ord_cond_2,
                 specs = ~ condition,
                 type = "response")

emmeans::emmeans(belief_ord_cond_2,
                 specs = ~ rating_type,
                 type = "response")

emmeans::emmeans(belief_ord_cond_2,
                 specs = ~ political_views,
                 at = list(political_views = 1:7),
                 type = "response")

emmeans::emmeans(belief_ord_cond_2,
                 specs = ~ political_views,
                 at = list(political_views = 1:7),
                 type = "response")
#
#tibble(participant_code = NA,
#       item_code = NA,
#       political_views = rep(1:7, times = 2),
#       fact_or_myth = c(rep("fact", times = 7), rep("myth", times = 7)),
#       condition = c(rep(1, times = 7), rep(2, times = 7)))
#
#belief_logit_dat %>%
#  select(item_category,
#         political_views, fact_or_myth, condition, rating_type,
#         rating_direction) %>%
#  mutate(participant_code = NA,
#         item_code = NA,
#         ord_cond_2_pred_prop_noranef = predict.glm(belief_ord_cond_2,
#                                                    type = "response")) %>%
#  group_by(item_category,
#         political_views, fact_or_myth, condition, rating_type,
#         rating_direction) %>%
#  slice_head(n = 1) %>%
#  ungroup() %>%
#  group_by(fact_or_myth, rating_direction) %>%
#  summarise(mean_prob = mean(ord_cond_2_pred_prop_noranef))
#
#crossing(political_views = 1:7,
#         fact_or_myth = c("fact", "myth"),
#         condition = 1:2,
#         rating_type = c("accuracy", "science"),
#         item_category = c("a", "h", "n", "v"))
#
#marginal_effects(belief_ord_cond_2, "political_views")
#
#belief_logit_dat %>%
#  mutate(ord_cond_2_pred_prop = predict.glm(belief_ord_cond_2, type = "response"),
#         ord_cond_2_pred_prop_noranef = predict.glm(belief_ord_cond_2,
#                                                    re.form = NA,
#                                                    type = "response")) %>% view()
#  ggplot(aes(x = political_views, y = ord_cond_2_pred_prop_noranef, color = rating_direction)) +
#  geom_line() +
#  scale_x_continuous(breaks = 1:7)  +
#  facet_wrap(~ fact_or_myth + rating_type + condition + item_category)
#
#predict.glm(belief_ord_cond_2,
#        data = belief_logit_dat,
#        type = "response")
#
```

### Mixed Effect Ordinal Logistic Regression (Bayesian)

Aligns with frequentist model across the board.

```{r}
belief_logit_dat <- belief_logit_dat %>%
  mutate(rating_direction_num = case_when(
    rating_direction == "decrease" ~ 1,
    rating_direction == "same" ~ 2,
    rating_direction == "increase" ~ 3,
  ))

belief_ord_cond_2_brm <- brm(rating_direction_num ~ 1 +
                                     condition +
                                     rating_type +
                                     fact_or_myth +
                                     item_category +
                                     political_views +
                                     (1 | participant_code) + (1 | item_code),
                             family = cumulative(link = "logit"),
                             data = belief_logit_dat,
                             file = "analysis/brms_fits/belief_ord_cond_2_brm")

summary(belief_ord_cond_2_brm)

# plot posterior samples
plot(belief_ord_cond_2_brm)
```

Probability estimates of the response levels.

Note that, beyond the chosen x, probabilities are conditional on other variables (covariates) being a) at the mean of the for continuous predictors and b) at the reference group for categorical predictors. That is, if considering the probability of each outcome (decrease, same, increase) as a function of political views, probability estimates are based on holding "condition" at 1, "rating_type" at accuracy, "fact_or_myth" at fact, and "item_category" at a. This can be adjusted with the `condition` argument within `brms::conditional_effects()` - see docs.

I should really functionalize/modularize this at some point. A lot of repitition - something like `brms::conditional_effects()` with these aesthetics mapped onto the data frames in the list would be cool. For another day...

```{r}
#conditional_effects(belief_ord_cond_2_brm, "political_views", categorical = TRUE)
#conditional_effects(belief_ord_cond_2_brm, "condition", categorical = TRUE)
#conditional_effects(belief_ord_cond_2_brm, "rating_type", categorical = TRUE)
#conditional_effects(belief_ord_cond_2_brm, "fact_or_myth", categorical = TRUE)
#conditional_effects(belief_ord_cond_2_brm, "item_category", categorical = TRUE)

# default re_form = NA, so no random effects used (nice for population effects)
belief_ord_cond_2_brm_effects <- conditional_effects(belief_ord_cond_2_brm,
                                                     categorical = TRUE)

# in case wanted
belief_ord_cond_2_brm_effects_wrandom <- conditional_effects(belief_ord_cond_2_brm,
                                                             re_formula = NULL,
                                                             categorical = TRUE)

# colors I like for signling decrease/same/increase
ordinal_colors <- c("darkred", "grey50", "#008000")

# stored data frames are in order from formula 
# condition estimates
belief_direction_plot_a <- belief_ord_cond_2_brm_effects[1] %>%
  data.frame() %>%
  janitor::clean_names() %>%
  mutate(condition_cats_cats = case_when(
    condition_cats_cats == 1 ~ "Decrease",
    condition_cats_cats == 2 ~ "Stay Same",
    condition_cats_cats == 3 ~ "Increase"
  ),
  condition_cats_cats = factor(condition_cats_cats,
                               levels = c("Decrease", "Stay Same", "Increase"))
  ) %>%
  ggplot(aes(x = condition_cats_condition,
             y = condition_cats_estimate,
             fill = condition_cats_cats)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  geom_errorbar(aes(ymin = condition_cats_lower,
                    ymax = condition_cats_upper),
                width = 0.25,
                position = position_dodge(width = 0.90)) +
  scale_fill_manual(values = ordinal_colors) +
  coord_cartesian(ylim = c(0,.60)) +
  labs(title = "A) Condition",
       x = "Condition",
       y = "Probability",
       fill = "Rating Direction") +
  raw_rating_theme()

# rating_type estimates
belief_direction_plot_b <- belief_ord_cond_2_brm_effects[2] %>%
  data.frame() %>%
  janitor::clean_names() %>%
  mutate(rating_type_cats_cats = case_when(
    rating_type_cats_cats == 1 ~ "Decrease",
    rating_type_cats_cats == 2 ~ "Stay Same",
    rating_type_cats_cats == 3 ~ "Increase"
  ),
  rating_type_cats_cats = factor(rating_type_cats_cats,
                               levels = c("Decrease", "Stay Same", "Increase")),
  
  rating_type_cats_rating_type = str_to_title(rating_type_cats_rating_type)) %>%
  ggplot(aes(x = rating_type_cats_rating_type,
             y = rating_type_cats_estimate,
             fill = rating_type_cats_cats)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  geom_errorbar(aes(ymin = rating_type_cats_lower,
                    ymax = rating_type_cats_upper),
                width = 0.25,
                position = position_dodge(width = 0.90)) +
  scale_fill_manual(values = ordinal_colors) +
  coord_cartesian(ylim = c(0,.60)) +
  labs(title = "B) Rating Type",
       x = "Rating Type",
       y = "Probability",
       fill = "Rating Direction") +
  raw_rating_theme()

# fact_or_myth estimates
belief_direction_plot_c <- belief_ord_cond_2_brm_effects[3] %>%
  data.frame() %>%
  janitor::clean_names() %>%
  mutate(fact_or_myth_cats_cats = case_when(
    fact_or_myth_cats_cats == 1 ~ "Decrease",
    fact_or_myth_cats_cats == 2 ~ "Stay Same",
    fact_or_myth_cats_cats == 3 ~ "Increase"
  ),
  fact_or_myth_cats_cats = factor(fact_or_myth_cats_cats,
                               levels = c("Decrease", "Stay Same", "Increase")),
  fact_or_myth_cats_fact_or_myth = str_to_title(fact_or_myth_cats_fact_or_myth)) %>%
  ggplot(aes(x = fact_or_myth_cats_fact_or_myth,
             y = fact_or_myth_cats_estimate,
             fill = fact_or_myth_cats_cats)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  geom_errorbar(aes(ymin = fact_or_myth_cats_lower,
                    ymax = fact_or_myth_cats_upper),
                width = 0.25,
                position = position_dodge(width = 0.90)) +
  scale_fill_manual(values = ordinal_colors) +
  coord_cartesian(ylim = c(0,.60)) +
  labs(title = "C) Fact or Myth",
       x = "Fact or Myth",
       y = "Probability",
       fill = "Rating Direction") +
  raw_rating_theme()

# item_category estimates
#belief_ord_cond_2_brm_effects[4] %>%
#  data.frame() %>%
#  janitor::clean_names() %>%
#  view()

# political_view estimates
belief_direction_plot_d <- belief_ord_cond_2_brm_effects[5] %>%
  data.frame() %>%
  janitor::clean_names() %>%
  mutate(political_views_cats_cats = case_when(
    political_views_cats_cats == 1 ~ "Decrease",
    political_views_cats_cats == 2 ~ "Stay Same",
    political_views_cats_cats == 3 ~ "Increase"
  ),
  political_views_cats_cats = factor(political_views_cats_cats,
                               levels = c("Decrease", "Stay Same", "Increase"))) %>%
  ggplot(aes(x = political_views_cats_political_views,
             y = political_views_cats_estimate,
             color = political_views_cats_cats)) +
  geom_ribbon(aes(ymin = political_views_cats_lower,
                  ymax = political_views_cats_upper,
                  group = political_views_cats_cats),
              fill = "lightgray",
              alpha = 0.30) +
  geom_line(aes(group = political_views_cats_cats),
            size = 2) +
  scale_color_manual(values = ordinal_colors) +
  coord_cartesian(ylim = c(0,.60)) +
  scale_x_continuous(breaks = 1:7) +
  labs(title = "D) Political Views",
       x = "Political Views",
       y = "Probability",
       color = "Rating Direction") +
  raw_rating_theme()
```

View and combine plots:

```{r}
#belief_direction_plot_a
#belief_direction_plot_b
#belief_direction_plot_c
#belief_direction_plot_d

belief_direction_plot_abcd <- (belief_direction_plot_a / belief_direction_plot_b) |
  (belief_direction_plot_c / belief_direction_plot_d)

belief_direction_plot_abcd

# save
#ggsave(filename = here::here(
#  "figs",
#  "figs_final",
#  paste0(format(Sys.time(), "%Y-%m-%d_%H-%M_%S_"), "brms_ord_mod_population_effects", ".png")
#  ),
#  plot = belief_direction_plot_abcd,
#  width = 14,
#  height = 12)
```

## Analysis (#3)

Sticking within an *ordinal* framework, let's move away from computing change first (e.g., from phase 1 to phase 2, did belief change [binary] or change in direction [ordinal]). That is, we're already fitting mixed models - what if we don't collapse across phase and instead treat phase as a fixed effect and, perhaps, give participants random slopes in belief across phases in the random effect structure?

To start, let's stick with 3 ordinal levels, computed from the original 1-7 Likert belief scale, such that ratings 1-3 = don't believe, 4 = neutral, and 5-7 = believe.

Prep data (for this model and the next [Analysis #4]:

```{r}
belief_multinom_dat <- belief_multinom_dat %>%
  mutate(belief_bin_three_fct = case_when(
    raw_rating <= 3 ~ "Don't Believe",
    raw_rating == 4 ~ "Neutral",
    raw_rating >= 5 ~ "Do Believe"
  ),
  belief_bin_three_num = case_when(
    raw_rating <= 3 ~ 1,
    raw_rating == 4 ~ 2,
    raw_rating >= 5 ~ 3
  ),
  belief_bin_three_fct = fct_reorder(belief_bin_three_fct, .x = belief_bin_three_num),
  belief_bin_seven_fct = factor(raw_rating),
  condition = factor(condition),
  phase = factor(phase))

# check levels
levels(belief_multinom_dat$belief_bin_three_fct)
levels(belief_multinom_dat$belief_bin_seven_fct)
levels(belief_multinom_dat$condition)
levels(belief_multinom_dat$phase)

# count level distributions
belief_multinom_dat %>%
  count(belief_bin_three_fct)

# mode across all = 5
belief_multinom_dat %>%
  count(belief_bin_seven_fct)
```

### Mixed Effect 3-Category Ordinal Logistic Regression w/ Phase (Frequentist)

```{r}
belief_logit_dat %>%
  count(rating_direction) # no excessive levels

# for ordinal::clmm, rating_direction needs to be a factor
belief_logit_dat$rating_direction <- factor(belief_logit_dat$rating_direction,
                                               levels = c("decrease", "same", "increase"))

levels(belief_logit_dat$rating_direction)

```

Empty/Null model. No random slopes:

```{r}
belief_ord_3_phase_null <- ordinal::clmm(belief_bin_three_fct ~ 1 +
                                         (1 | participant_code) + (1 | item_code),
                                       link = "logit", # proportional odds
                                       data = belief_multinom_dat)

summary(belief_ord_3_phase_null)
```

Conditional models:

```{r}
belief_ord_3_phase_cond_1 <- ordinal::clmm(belief_bin_three_fct ~ 1 +
                                           condition +
                                           rating_type +
                                           fact_or_myth +
                                           phase +
                                         (1 | participant_code) + (1 | item_code),
                                       link = "logit", # proportional odds
                                       data = belief_multinom_dat)

summary(belief_ord_3_phase_cond_1)

belief_ord_3_phase_cond_2 <- ordinal::clmm(belief_bin_three_fct ~ 1 +
                                           condition +
                                           rating_type +
                                           fact_or_myth +
                                           phase +
                                           item_category +
                                           political_views +
                                         (1 | participant_code) + (1 | item_code),
                                       link = "logit", # proportional odds
                                       data = belief_multinom_dat)

summary(belief_ord_3_phase_cond_2)

belief_ord_3_phase_cond_3 <- ordinal::clmm(belief_bin_three_fct ~ 1 +
                                           condition * phase +
                                           rating_type +
                                           fact_or_myth +
                                           item_category +
                                           political_views +
                                         (1 | participant_code) + (1 | item_code),
                                       link = "logit", # proportional odds
                                       data = belief_multinom_dat)

summary(belief_ord_3_phase_cond_3)
```

Odds ratios:

```{r}
exp(belief_ord_3_phase_cond_3$coefficients)
```

### Mixed Effect 3-Category Ordinal Logistic Regression w/ Phase (Bayesian)

Fit the full model from above in a Bayesian framework.

Note. "NEW" because I previously forgot to make condition a factor. No big deal without an interaction (`brms` seems to assume it is a factor; see earlier models), but with...and it changes interaction interpratation (e.g., when condition = 0). 

```{r}
belief_ord_3_phase_cond_3_NEW_brm <- brm(belief_bin_three_num ~ 1 +
                                           condition * phase +
                                           rating_type +
                                           fact_or_myth +
                                           item_category +
                                           political_views +
                                         (1 | participant_code) + (1 | item_code),
                             family = cumulative(link = "logit"),
                             data = belief_multinom_dat,
                             file = "analysis/brms_fits/belief_ord_3_phase_cond_3_NEW_brm")

summary(belief_ord_3_phase_cond_3_NEW_brm)
plot(belief_ord_3_phase_cond_3_NEW_brm)

#summary(belief_ord_3_phase_cond_3_brm)
```

Predict/plot...

*Note*: Plots are same after refitting with condition as continuous. Interestingly, it's clearly modeled as a factor in NEW (e.g., output = condition2, indicating reference = 1), but conditional_effects requires a numeric input. Tried quoting and it throws an error, see below. Don't know if this is a bug or just idiosyncratic, but something to keep in mind. Perhaps this is on me - I should have created a new character/factor column so there is no ambiguity - but even so.

```{r}
# default re_form = NA, so no random effects used (nice for population effects)
# all - namely for plotting plotting political_views effect (when condition = 1)
# modeled as continuous :( but can just grab estimates when 1

# changed model - modeled as factor - but needs continuous input here?
belief_ord_3_phase_cond_3_brm_polit_condit <- data.frame(condition = c(1, 1),
                                                         phase = c("p1", "p2"))

belief_ord_3_phase_cond_3_brm_NEW_effects <-
  conditional_effects(belief_ord_3_phase_cond_3_brm,
                      conditions = belief_ord_3_phase_cond_3_brm_polit_condit,
                      categorical = TRUE)

# for interaction
# could add more factors to this to get more combos for plotting
# those not included are held at mean or reference group
#belief_ord_3_phase_cond_3_brm_int_condit <- data.frame(condition = c("1","2"),
#                                                       phase = factor(c("p1", "p2")))

# original variable numeric? model output suggests otherwise (e.g., condition2)
belief_ord_3_phase_cond_3_brm_int_NEW_condit <- data.frame(condition = c(1,1,2,2),
                                                       phase = factor(c("p1", "p2", "p1", "p2")))

view(belief_ord_3_phase_cond_3_brm_int_NEW_condit)

belief_ord_3_phase_cond_3_brm_int_NEW_effects <-
  conditional_effects(belief_ord_3_phase_cond_3_brm,
                      conditions = belief_ord_3_phase_cond_3_brm_int_NEW_condit,
                      categorical = TRUE)


# colors I like
ordinal_colors <- c("darkred", "grey50", "#008000")


# extract predicted probabilities

# political_view effect at:
# condition = 1, phases 1 and 2, rating_type = accuracy,
# fact_or_myth = fact, item category = a

belief_ord_3_phase_plot_b <- belief_ord_3_phase_cond_3_brm_NEW_effects[6] %>%
  data.frame() %>%
  janitor::clean_names() %>%
  mutate(political_views_cats_cats = case_when(
    political_views_cats_cats == 1 ~ "Don't Believe",
    political_views_cats_cats == 2 ~ "Neutral",
    political_views_cats_cats == 3 ~ "Do Believe"
  ),
  political_views_cats_cats = factor(political_views_cats_cats,
                               levels = c("Don't Believe", "Neutral", "Do Believe")),
  political_views_cats_phase = ifelse(political_views_cats_phase == "p1",
                                      "Phase 1", "Phase 2")
  ) %>%
  ggplot(aes(x = political_views_cats_political_views,
             y = political_views_cats_estimate,
             color = political_views_cats_cats)) +
  geom_ribbon(aes(ymin = political_views_cats_lower,
                  ymax = political_views_cats_upper,
                  group = political_views_cats_cats),
              fill = "lightgray",
              alpha = 0.30) +
  geom_line(aes(group = political_views_cats_cats),
            size = 2) +
  scale_color_manual(values = ordinal_colors) +
  coord_cartesian(ylim = c(0,1)) +
  scale_x_continuous(breaks = 1:7) +
  labs(title = "B) Political Views",
       x = "Political Views",
       y = "Probability",
       color = "Belief") +
  facet_wrap(~ political_views_cats_phase) +
  raw_rating_theme()



# condition / phase interaction at:
# rating_type = accuracy, political_views = mean (3.27),
# item_category = a, fact_or_myth = fact
belief_ord_3_phase_plot_a <- belief_ord_3_phase_cond_3_brm_int_NEW_effects[1] %>%
  data.frame() %>%
  janitor::clean_names() %>%
  mutate(condition_cats_cats = case_when(
    condition_cats_cats == 1 ~ "Don't Believe",
    condition_cats_cats == 2 ~ "Neutral",
    condition_cats_cats == 3 ~ "Do Believe"
  ),
  condition_cats_cats = factor(condition_cats_cats,
                               levels = c("Don't Believe", "Neutral", "Do Believe")),
  condition_cats_phase = ifelse(condition_cats_phase == "p1",
                                      "Phase 1", "Phase 2")
  ) %>%
  # condition counted as continuous (though coef matches clmm mod)
  # grab only rows where condition == 1 or 2
  filter(condition_cats_condition == 1 |
           condition_cats_condition == 2) %>%
  ggplot(aes(x = factor(condition_cats_condition),
             y = condition_cats_estimate,
             fill = condition_cats_cats)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  geom_errorbar(aes(ymin = condition_cats_lower,
                    ymax = condition_cats_upper),
                width = 0.25,
                position = position_dodge(width = 0.90)) +
  scale_fill_manual(values = ordinal_colors) +
  coord_cartesian(ylim = c(0,1)) +
  facet_wrap(~ condition_cats_phase) +
  labs(title = "A) Condition X Phase Interaction",
       x = "Condition",
       y = "Probability",
       fill = "Belief") +
  raw_rating_theme()

```

Compile and save:

```{r}
belief_ord_3_phase_plot_ab <- belief_ord_3_phase_plot_a /
  belief_ord_3_phase_plot_b

belief_ord_3_phase_plot_ab

#ggsave(filename = here::here(
#  "figs",
#  "figs_final",
#  paste0(format(Sys.time(), "%Y-%m-%d_%H-%M_%S_"), "belief_ord_3_phase_plot_ab", ".png")
#  ),
#  plot = belief_ord_3_phase_plot_ab,
#  width = 14,
#  height = 10)
```

## SKIP Analysis (#4)

Sticking within an *ordinal* framework, 7-categories?

### SKIP Mixed Effect 7-Category Ordinal Logistic Regression w/ Phase (Frequentist)

### SKIP Mixed Effect 7-Category Ordinal Logistic Regression w/ Phase (Bayesian)

The 3-category ordinal model took ~1.5 hours to fit, so...maybe some other time.

# Reinforcement / Suppression

## R/S Missing Data Analysis

What percentage of data is missing at each R/S level / retrieval practice combination (e.g., R/S -4 for practiced items)?

Given the nature of the metric, a lot of data is missing. More importantly, this missingness looks systematic (MNAR):

```{r}
rschange %>%
  filter(retrieval_practice != "all") %>%
  mutate(rs_level = fct_reorder(rs_level, rs_level_num)) %>%
  group_by(retrieval_practice, rs_level_num) %>%
  summarise(prop_missing = mean(missing_data)) %>%
  ungroup() %>%
  mutate(retrieval_practice = ifelse(retrieval_practice == "rppos",
                                     "Retrieval Practice",
                                     "No Retrieval Practice")) %>%
  ggplot(aes(x = factor(rs_level_num), y = prop_missing)) +
  geom_bar(stat = "identity",
           fill = "#134e13") +
  facet_wrap(~ retrieval_practice, ncol = 1) +
  coord_cartesian(ylim = c(0,1)) +
  geom_hline(yintercept = .5,
             color = "red",
             linetype = "dashed",
             size = 2) +
  labs(title = "A) Observed Missingness",
       x = "R/S Level",
       y = "Proportion Missing") +
  raw_rating_theme()
```

Prep data for modeling (remove aggregate "all" level for each person):

```{r}
rschange_mod_dat <- rschange %>%
  filter(retrieval_practice != "all") %>%
  # for modeling, set rs_level reference to 0
  # "Beliefs that were unmentioned and unrelated to those mentioned
  # received a score of 0 on the R/S scale."
  
  # don't need both of these factors, but
  mutate(rs_level = factor(rs_level, levels = c("zero",
                                                "neg4",
                                                "neg3",
                                                "neg2",
                                                "neg1",
                                                "pos1",
                                                "pos2",
                                                "pos3",
                                                "pos4")),
         rs_level_num_fac = factor(rs_level_num, levels = c("0",
                                                            "-4",
                                                            "-3",
                                                            "-2",
                                                            "-1",
                                                            "1",
                                                            "2",
                                                            "3",
                                                            "4")))

levels(rschange_mod_dat$rs_level_num_fac)
```

## Analyses (#4)

### Mixed Effect Logistic Regression (Frequentist)

And analyze via multilevel logistic regression with `lme4::glmer` (frequentist).

No null model first because not really interested in nuances of random effects - the data is structured in such a way that they should be included (multiple observations per participant) so they are included. Here, we are interested in systematic missingness as a function of potential predictors in subsequent models (e.g., $Belief\:Change \sim RS\:Level + Retrieval\:Practice + Condition + ...$).

Note: treating RS level as continuous. Treating it as a factor (eventually what it is aggregated to in the paper) leads to convergence issues as it requires estimating 8 comparisons.

```{r}
rschange_missing_cond_1 <- glmer(missing_data ~ retrieval_practice + rs_level_num + condition +
                                   (1 | response_id),
                              family = binomial(link = "logit"), # bernoulli, but special case of binom
                              data = rschange_mod_dat)

summary(rschange_missing_cond_1)
```

Table. Nice one for viewing in R/RMarkdown, code from `stargazer` for paper:

```{r}
broom.mixed::tidy(rschange_missing_cond_1) %>%
  mutate(estimate_oddratio = ifelse(effect == "fixed", exp(estimate), NA),
         .after = estimate) %>%
  select(-statistic)

#stargazer::stargazer(rschange_missing_cond_1,
#                     type = "latex",
#                     out = here::here("figs", "figs_temp", "rschange_cond_1_tab.tex"))
```

Plot predicted missingness as a function of retrieval practice and R/S level (the statistically significant predictors):

```{r}
rs_missingness_plot_a <- emmeans::emmeans(rschange_missing_cond_1,
                 specs = ~ retrieval_practice,
                 type = "response") %>%
  data.frame() %>%
  mutate(retrieval_practice = ifelse(retrieval_practice == "rpneg",
                                     "Not Practiced",
                                     "Practiced")) %>%
  ggplot(aes(x = retrieval_practice, y = prob)) +
  geom_bar(stat = "identity",
           fill = "#134e13") +
  geom_errorbar(aes(ymin = asymp.LCL,
                    ymax = asymp.UCL),
                width = 0.25,
                color = "black") +
  coord_cartesian(ylim = c(0.3, 0.8)) +
  labs(title = "A) Retrieval Practice",
       x = "Retrieval Practice",
       y = "Missing Probability") +
  raw_rating_theme()

rs_missingness_plot_b <- emmeans::emmeans(rschange_missing_cond_1,
                 specs = ~ rs_level_num,
                 at = list(rs_level_num = -4:4),
                 type = "response") %>%
  data.frame() %>%
  ggplot(aes(x = rs_level_num, y = prob)) +
  geom_ribbon(aes(ymin = asymp.LCL,
                ymax = asymp.UCL),
              fill = "lightgray",
              alpha = 0.30) +
  geom_line(size = 2,
            color = "#134e13") +
  scale_x_continuous(breaks = -4:4) +
  coord_cartesian(ylim = c(0.3, 0.75)) +
  labs(title = "B) Reinforcement/Supression (RS) Level",
       x = "Reinforcement/Supression (RS) Level",
       y = "Missing Probability") +
  raw_rating_theme()
```

Compile and plot:

```{r}
rs_missingness_plot_ab <- rs_missingness_plot_a + rs_missingness_plot_b

rs_missingness_plot_ab

#ggsave(filename = here::here(
#  "figs",
#  "figs_final",
#  paste0(format(Sys.time(), "%Y-%m-%d_%H-%M_%S_"), "rs_missingness_plot_ab", ".png")
#  ),
#  plot = rs_missingness_plot_ab,
#  width = 14)
```


### Mixed Effect Logistic Regression (Bayesian)

Bayesian version for comparison:

```{r}
rschange_missing_cond_1_brm <- brm(missing_data ~ retrieval_practice + rs_level_num + condition +
                              (1 | response_id),
                            family = bernoulli(link = "logit"), # only 0/1 so more efficient
                            data = rschange_mod_dat,
                            file = "analysis/brms_fits/rschange_missing_cond_1_brm")

summary(rschange_missing_cond_1_brm)
plot(rschange_missing_cond_1_brm)
```

# Belief Synchronicity

## "Changing Together"

The original paper describes assessing belief synchronization by comparing - across condition and retrieval practice - the proportion of beliefs that increased together and decreased together. "Together" = each pair of individuals within a network, whether or not they collaborated.

To recap, from 2021-11_processing.Rmd:

"...there are 462 rows in the raw because within each network there are 12 individuals and thus (`ncol(combn(12, 2))`) = 66 pairs. With 7 networks per condition, $7 \times 66 = 462$.

Pivoting everything should return a data with $462 \times 2 = 924$ for each of the 4 rppos/rpneg vs. increasetog/decreasetog combinations, so $924 \times 4 = 3696$."

There was **no row level information in the raw data indicating what pair/network each proportion belongs to**, so no way to account for network dependence - of which there should be a ton. Within increasing/decreasing together levels, if we assume each pair is independent (extremely tenuous, but same as ANOVA in the paper), we can do beta regression. If there was some way to know what network each pair (row) is derived from, mixed effect beta regression, with random effect(s) for network, would be the best option.

For now, just doing beta regression in place of the ANOVA reported in the paper. This will not be going in my paper (which is more about belief change/measurement), largely because beliefs increasing/decreasing together in this context is different from the way I conceptualize beliefs in the rest of my paper - the beliefs these data are based on are the collapsed accuracy/scientific support ratings, $z$-scored within participants. Thus, this will go in the Appendix as "Belief Change Synchronicity Beta Regression Re-analysis"

### Beta Regression (Frequentist; Appendix B)

Check data

```{r}
synch %>%
  filter(is.na(prop)) %>% 
  group_by(actual_pair) %>%
  slice_head(n = 1) %>%
  nrow()

# 22 pairs / 924 have NA prop values
```

Replicate ANOVA as reported in paper? Yes. 

```{r}
paper_aov_type2ss <- rstatix::anova_test(data = synch,
                      dv = prop,
                      between = condition,
                      within = c(retrieval_practice, change_direction),
                      wid = actual_pair)

paper_aov_type3ss <- rstatix::anova_test(data = synch,
                      dv = prop,
                      between = condition,
                      within = c(retrieval_practice, change_direction),
                      wid = actual_pair,
                      type = 3)

rstatix::get_anova_table(paper_aov_type2ss)
rstatix::get_anova_table(paper_aov_type3ss)
```

Fit similar model, but via mixed effects beta regression. This has the benifit of a) respecting proportion boundaries and b) respecting nesting/dependence present in the data. I'm uncertain *either* of these tests are appropriate for power reasons (3-way interaction), but for now, let's just see what happens to the effects...

```{r}
# zoib
# betareg

# https://github.com/glmmTMB/glmmTMB/pull/497/commits/0366610b3095589698d90810c4bda1d32fd65afd
# recently implemented! exciting
# interpretation though?
synch_prop_cond_1 <- glmmTMB::glmmTMB(prop ~ 1 +
                                        retrieval_practice *
                                        change_direction *
                                        condition +
                                        # nest pairs in inferred networks
                                        (1 | actual_net/actual_pair),
                                      family = glmmTMB::beta_family, # default = logit
                                      zi = ~1, # for 0 inflation
                                      data = synch)

summary(synch_prop_cond_1)
exp(coefficients(synch_prop_cond_1))
#min(synch$prop, na.rm = TRUE)
#max(synch$prop, na.rm = TRUE)
```

Replicates and then some - *all effects statistically significant*.

Replicate plot and inspect further:

```{r}
emmeans::emmeans(synch_prop_cond_1,
                 specs = ~ retrieval_practice * change_direction * condition,
                 type = "response") %>%
  data.frame() %>%
  filter(change_direction == "increasetog") %>%
  ggplot(aes(x = condition, y = response, fill = retrieval_practice)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  facet_wrap(~ retrieval_practice)

emmeans::emmeans(synch_prop_cond_1,
                 specs = ~ retrieval_practice * change_direction * condition,
                 type = "response") %>%
  data.frame() %>%
  filter(change_direction == "decreasetog") %>%
  ggplot(aes(x = condition, y = response, fill = retrieval_practice)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  facet_wrap(~ retrieval_practice)
```

New plot, respecting nested structure (though very little variance in estimates between pair lines):

```{r}
synch %>%
  predict(pred_prop = predict(synch_prop_cond_1,
                              type = "response",
                              re.form = NA))

synch_aug <- broom.mixed::augment(synch_prop_cond_1, data = synch %>%
                                    filter(!is.na(prop)))

synch_aug %>%
  mutate(pred_odds = exp(.fitted),
         pred_prop = pred_odds / (1 + pred_odds)) %>%
  ggplot(aes(x = .resid,
             y = .fitted)) +
  geom_point()

synch_int_plot <- synch_aug %>%
  mutate(pred_odds = exp(.fitted),
         pred_prop = pred_odds / (1 + pred_odds)) %>%
  # aesthetic mutates
  mutate(condition = ifelse(condition == "control",
                            "Control", "Experimental"),
         change_direction = ifelse(change_direction == "increasetog",
                                   "Increase Together", "Decrease Together"),
         retrieval_practice = ifelse(retrieval_practice == "rppos",
                                     "Practiced", "Not Practiced")) %>%
  ggplot(aes(x = retrieval_practice,
             y = pred_prop)) +
  geom_point() +
  geom_line(aes(group = actual_pair, color = condition)) +
  facet_wrap(~ condition + change_direction) +
  coord_cartesian(ylim = c(0.1, 0.5)) +
  scale_color_manual(values = c("#000080", "darkred")) +
  labs(x = "Statement Practice",
       y = "Predicted Proportion",
       color = "Condition") +
  raw_rating_theme()
```

View and save:

```{r}
synch_int_plot
#ggsave(filename = here::here(
#  "figs",
#  "figs_final",
#  paste0(format(Sys.time(), "%Y-%m-%d_%H-%M_%S_"), "synch_int_plot", ".png")
#  ),
#  plot = synch_int_plot,
#  width = 14,
#  height = 10)
```


### Beta Regression (Bayesian; Appendix B)

```{r}
#synch_prop_cond_1_brm <- brm(prop ~ 1 +
#                           retrieval_practice +
#                           change_direction +
#                           condition +
#                           (1 | actual_net/actual_pair),
#                            family = zero_inflated_beta(link = "logit"),
#                            data = synch,
#                            file = "analysis/brms_fits/synch_prop_cond_1_brm")
```

# Session Info

For reproducibility

```{r}
sessionInfo()
```
